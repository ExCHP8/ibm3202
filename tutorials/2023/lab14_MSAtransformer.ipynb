{"cells":[{"cell_type":"markdown","source":["# Theoretical background"],"metadata":{"id":"jKVlPhOZfLHU"}},{"cell_type":"markdown","source":["In this notebook, we will fit a MSA to a Pott's model using the trained MSA Transformer (reference below), an AI tool developed to maximize the retrieval of **coevolution contacts from a shallow yet highly diverse MSA**. In practice, this module performs as well as a vanilla fitting to a Pott's model or the ESM-1b protein language model with an **MSA of only 16 sequences**, and increasing the diversity and number of these seequences only improves beyond those results.\n","\n","In this notebook we will:\n","- Download and view the structure and sequence of *T. hennahi* myohemerithryn, deposited in the PDB. In principle this can be done with any other PDB or protein sequence and model from Alphafold2.\n","- Search for similar sequences to your target in the Colabfold database and retrieve its MSA. This could be done for any sequence you are interested in.\n","- Predict the coevolutionary contacts in your MSA and compare them with the structural contacts.\n","-Perform a simulated annealing simulation in Gō-Models (alpha-Carbon structure based model) considering the radius of interaction independent of the protein sequence (no sidechain effect on the prediction).\n","-Compare the results from the simulation and the original PDB structure (or your model).\n","\n","Rao, R.M., Liu, J., Verkuil, R., Meier, J., Canny, J., Abbeel, P., Sercu, T. &amp; Rives, A.. (2021). MSA Transformer. <i>Proceedings of the 38th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 139:8844-8856 Available from https://proceedings.mlr.press/v139/rao21a.html.\n","\n"],"metadata":{"id":"EPR0pUL2fPQh"}},{"cell_type":"markdown","metadata":{"id":"U0ukYqqzateL"},"source":["### Setup (Colab)\n","\n","If in colab, you will need to install these dependencies, download this data, and the model weights. If you are not in colab, you may have some of these already installed, or may need to install other dependencies (e.g. pytorch)."]},{"cell_type":"markdown","metadata":{"id":"IiB2IaU6QyF9"},"source":["### Install dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"I2MLDXLJQmnB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698083724276,"user_tz":180,"elapsed":44943,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}},"outputId":"23513f0a-263b-4761-9136-6841dd4e4152"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting biopython\n","  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.5/3.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting biotite\n","  Downloading biotite-0.38.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting py3Dmol\n","  Downloading py3Dmol-2.0.4-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.23.5)\n","Requirement already satisfied: requests>=2.12 in /usr/local/lib/python3.10/dist-packages (from biotite) (2.31.0)\n","Requirement already satisfied: msgpack>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from biotite) (1.0.7)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from biotite) (3.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.12->biotite) (2023.7.22)\n","Installing collected packages: py3Dmol, biopython, biotite\n","Successfully installed biopython-1.81 biotite-0.38.0 py3Dmol-2.0.4\n","Collecting git+https://github.com/facebookresearch/esm.git\n","  Cloning https://github.com/facebookresearch/esm.git to /tmp/pip-req-build-0ske5b70\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/esm.git /tmp/pip-req-build-0ske5b70\n","  Resolved https://github.com/facebookresearch/esm.git to commit 2b369911bb5b4b0dda914521b9475cad1656b2ac\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: fair-esm\n","  Building wheel for fair-esm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fair-esm: filename=fair_esm-2.0.1-py3-none-any.whl size=105381 sha256=710a5c3af0b79df244c2b885ab5662718f281aa2a3e1b89e471d8465679bcec3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fld82p8c/wheels/f3/b2/ec/4db0b108f6367c7563f99b2445e1137d486003fb2f9bfd2f53\n","Successfully built fair-esm\n","Installing collected packages: fair-esm\n","Successfully installed fair-esm-2.0.1\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libaria2-0 libc-ares2\n","The following NEW packages will be installed:\n","  aria2 libaria2-0 libc-ares2\n","0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n","Need to get 1,513 kB of archives.\n","After this operation, 5,441 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.2 [45.0 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libaria2-0 amd64 1.36.0-1 [1,086 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 aria2 amd64 1.36.0-1 [381 kB]\n","Fetched 1,513 kB in 2s (701 kB/s)\n","Selecting previously unselected package libc-ares2:amd64.\n","(Reading database ... 120874 files and directories currently installed.)\n","Preparing to unpack .../libc-ares2_1.18.1-1ubuntu0.22.04.2_amd64.deb ...\n","Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n","Selecting previously unselected package libaria2-0:amd64.\n","Preparing to unpack .../libaria2-0_1.36.0-1_amd64.deb ...\n","Unpacking libaria2-0:amd64 (1.36.0-1) ...\n","Selecting previously unselected package aria2.\n","Preparing to unpack .../aria2_1.36.0-1_amd64.deb ...\n","Unpacking aria2 (1.36.0-1) ...\n","Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.2) ...\n","Setting up libaria2-0:amd64 (1.36.0-1) ...\n","Setting up aria2 (1.36.0-1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n"]}],"source":["!python -m pip install biopython biotite py3Dmol\n","!python -m pip install git+https://github.com/facebookresearch/esm.git\n","!apt-get install aria2"]},{"cell_type":"markdown","metadata":{"id":"Nad5sAXqREhx"},"source":["### Download model weights\n","This download code is technically unnecessary. ESM will download weights automatically. However, it's *really* slow on colab. aria2c is much faster."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8e2GzK00RT_L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698083753770,"user_tz":180,"elapsed":14033,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}},"outputId":"3bab1de5-7eaa-4dbe-96ce-b18b97ed1f06"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","10/23 17:55:39 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n","\n","10/23 17:55:40 [\u001b[1;31mERROR\u001b[0m] CUID#7 - Download aborted. URI=https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n","Exception: [AbstractCommand.cc:351] errorCode=22 URI=https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n","  -> [HttpSkipResponseCommand.cc:239] errorCode=22 The response status is not successful. status=403\n","\n","10/23 17:55:40 [\u001b[1;32mNOTICE\u001b[0m] Download GID#7502976d23dbce74 not complete: \n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","750297|\u001b[1;31mERR\u001b[0m |       0B/s|https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n","\n","Status Legend:\n","(ERR):error occurred.\n","\n","aria2 will resume download if the transfer is restarted.\n","If there are any errors, then see the log file. See '-l' option in help/man page for details.\n","\n","10/23 17:55:40 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n","\n","10/23 17:55:41 [\u001b[1;31mERROR\u001b[0m] CUID#7 - Download aborted. URI=https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n","Exception: [AbstractCommand.cc:351] errorCode=22 URI=https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n","  -> [HttpSkipResponseCommand.cc:239] errorCode=22 The response status is not successful. status=403\n","\n","10/23 17:55:41 [\u001b[1;32mNOTICE\u001b[0m] Download GID#0abf5c7938a15269 not complete: \n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","0abf5c|\u001b[1;31mERR\u001b[0m |       0B/s|https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n","\n","Status Legend:\n","(ERR):error occurred.\n","\n","aria2 will resume download if the transfer is restarted.\n","If there are any errors, then see the log file. See '-l' option in help/man page for details.\n","\n","10/23 17:55:41 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n","\u001b[0m\n","10/23 17:55:53 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /root/.cache/torch/hub/checkpoints/esm_msa1b_t12_100M_UR50S.pt\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","db52eb|\u001b[1;32mOK\u001b[0m  |   120MiB/s|/root/.cache/torch/hub/checkpoints/esm_msa1b_t12_100M_UR50S.pt\n","\n","Status Legend:\n","(OK):download completed.\n","\n","10/23 17:55:53 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n","\n","10/23 17:55:53 [\u001b[1;32mNOTICE\u001b[0m] Download complete: /root/.cache/torch/hub/checkpoints/esm_msa1b_t12_100M_UR50S-contact-regression.pt\n","\n","Download Results:\n","gid   |stat|avg speed  |path/URI\n","======+====+===========+=======================================================\n","536b2e|\u001b[1;32mOK\u001b[0m  |   171KiB/s|/root/.cache/torch/hub/checkpoints/esm_msa1b_t12_100M_UR50S-contact-regression.pt\n","\n","Status Legend:\n","(OK):download completed.\n"]}],"source":["!mkdir -p /root/.cache/torch/hub/checkpoints\n","!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8\\\n","    https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n","!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8\\\n","    https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n","!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8\\\n","    https://dl.fbaipublicfiles.com/fair-esm/models/esm_msa1b_t12_100M_UR50S.pt\n","!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8\\\n","    https://dl.fbaipublicfiles.com/fair-esm/regression/esm_msa1b_t12_100M_UR50S-contact-regression.pt"]},{"cell_type":"markdown","metadata":{"id":"q1eZWXv1bxGl"},"source":["## Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fQ8ztOjvQbJV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698083758450,"user_tz":180,"elapsed":4703,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}},"outputId":"508da5cf-ed1f-44b2-baf5-8706e7922f61"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.grad_mode.set_grad_enabled at 0x7fa832f856c0>"]},"metadata":{},"execution_count":3}],"source":["from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n","import itertools\n","import os\n","import string\n","from pathlib import Path\n","\n","import numpy as np\n","import torch\n","from scipy.spatial.distance import squareform, pdist, cdist\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from Bio import SeqIO\n","import biotite.structure as bs\n","from biotite.structure.io.pdbx import PDBxFile, get_structure\n","from biotite.database import rcsb\n","from tqdm import tqdm\n","import pandas as pd\n","\n","import esm\n","\n","torch.set_grad_enabled(False)"]},{"cell_type":"markdown","metadata":{"id":"i7iXPaDKZ5vx"},"source":["## Define Functions"]},{"cell_type":"markdown","metadata":{"id":"rb4cDoG2ns91"},"source":["### Parsing alignments"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Lpt-Ijz2T6zF","executionInfo":{"status":"ok","timestamp":1698083758450,"user_tz":180,"elapsed":27,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"outputs":[],"source":["# This is an efficient way to delete lowercase characters and insertion characters from a string\n","deletekeys = dict.fromkeys(string.ascii_lowercase)\n","deletekeys[\".\"] = None\n","deletekeys[\"*\"] = None\n","translation = str.maketrans(deletekeys)\n","\n","def read_sequence(filename: str) -> Tuple[str, str]:\n","    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n","    record = next(SeqIO.parse(filename, \"fasta\"))\n","    return record.description, str(record.seq)\n","\n","def remove_insertions(sequence: str) -> str:\n","    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n","    return sequence.translate(translation)\n","\n","def read_msa(filename: str) -> List[Tuple[str, str]]:\n","    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n","    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"]},{"cell_type":"markdown","metadata":{"id":"tV3WCbn6aXL7"},"source":["### Converting structures to contacts\n","\n","There are many ways to define a protein contact. Here we're using the definition of 8 angstroms between carbon beta atoms. Note that the position of the carbon beta is imputed from the position of the N, CA, and C atoms for each residue."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"n4FBkOUaWuXb","executionInfo":{"status":"ok","timestamp":1698083758451,"user_tz":180,"elapsed":25,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"outputs":[],"source":["def extend(a, b, c, L, A, D):\n","    \"\"\"\n","    input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n","    output: 4th coord\n","    \"\"\"\n","\n","    def normalize(x):\n","        return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n","\n","    bc = normalize(b - c)\n","    n = normalize(np.cross(b - a, bc))\n","    m = [bc, np.cross(n, bc), n]\n","    d = [L * np.cos(A), L * np.sin(A) * np.cos(D), -L * np.sin(A) * np.sin(D)]\n","    return c + sum([m * d for m, d in zip(m, d)])\n","\n","\n","def contacts_from_pdb(\n","    structure: bs.AtomArray,\n","    distance_threshold: float = 8.0,\n","    chain: Optional[str] = None,\n",") -> np.ndarray:\n","    mask = ~structure.hetero\n","    if chain is not None:\n","        mask &= structure.chain_id == chain\n","\n","    N = structure.coord[mask & (structure.atom_name == \"N\")]\n","    CA = structure.coord[mask & (structure.atom_name == \"CA\")]\n","    C = structure.coord[mask & (structure.atom_name == \"C\")]\n","\n","    Cbeta = extend(C, N, CA, 1.522, 1.927, -2.143)\n","    dist = squareform(pdist(Cbeta))\n","\n","    contacts = dist < distance_threshold\n","    contacts = contacts.astype(np.int64)\n","    contacts[np.isnan(dist)] = -1\n","    return contacts"]},{"cell_type":"markdown","metadata":{"id":"mqwybh2Tn_Ou"},"source":["### Subsampling MSA"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"dSdxag5OmOmK","executionInfo":{"status":"ok","timestamp":1698083758451,"user_tz":180,"elapsed":25,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"outputs":[],"source":["# Select sequences from the MSA to maximize the hamming distance\n","# Alternatively, can use hhfilter\n","def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n","    assert mode in (\"max\", \"min\")\n","    if len(msa) <= num_seqs:\n","        return msa\n","\n","    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n","\n","    optfunc = np.argmax if mode == \"max\" else np.argmin\n","    all_indices = np.arange(len(msa))\n","    indices = [0]\n","    pairwise_distances = np.zeros((0, len(msa)))\n","    for _ in range(num_seqs - 1):\n","        dist = cdist(array[indices[-1:]], array, \"hamming\")\n","        pairwise_distances = np.concatenate([pairwise_distances, dist])\n","        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n","        shifted_index = optfunc(shifted_distance)\n","        index = np.delete(all_indices, indices)[shifted_index]\n","        indices.append(index)\n","    indices = sorted(indices)\n","    return [msa[idx] for idx in indices]"]},{"cell_type":"markdown","metadata":{"id":"lW5thQpSn0Rp"},"source":["### Compute contact precisions"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"c7T9xWTXeIaR","executionInfo":{"status":"ok","timestamp":1698083758451,"user_tz":180,"elapsed":25,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"outputs":[],"source":["def compute_precisions(\n","    predictions: torch.Tensor,\n","    targets: torch.Tensor,\n","    src_lengths: Optional[torch.Tensor] = None,\n","    minsep: int = 6,\n","    maxsep: Optional[int] = None,\n","    override_length: Optional[int] = None,  # for casp\n","):\n","    if isinstance(predictions, np.ndarray):\n","        predictions = torch.from_numpy(predictions)\n","    if isinstance(targets, np.ndarray):\n","        targets = torch.from_numpy(targets)\n","    if predictions.dim() == 2:\n","        predictions = predictions.unsqueeze(0)\n","    if targets.dim() == 2:\n","        targets = targets.unsqueeze(0)\n","    override_length = (targets[0, 0] >= 0).sum()\n","\n","    # Check sizes\n","    if predictions.size() != targets.size():\n","        raise ValueError(\n","            f\"Size mismatch. Received predictions of size {predictions.size()}, \"\n","            f\"targets of size {targets.size()}\"\n","        )\n","    device = predictions.device\n","\n","    batch_size, seqlen, _ = predictions.size()\n","    seqlen_range = torch.arange(seqlen, device=device)\n","\n","    sep = seqlen_range.unsqueeze(0) - seqlen_range.unsqueeze(1)\n","    sep = sep.unsqueeze(0)\n","    valid_mask = sep >= minsep\n","    valid_mask = valid_mask & (targets >= 0)  # negative targets are invalid\n","\n","    if maxsep is not None:\n","        valid_mask &= sep < maxsep\n","\n","    if src_lengths is not None:\n","        valid = seqlen_range.unsqueeze(0) < src_lengths.unsqueeze(1)\n","        valid_mask &= valid.unsqueeze(1) & valid.unsqueeze(2)\n","    else:\n","        src_lengths = torch.full([batch_size], seqlen, device=device, dtype=torch.long)\n","\n","    predictions = predictions.masked_fill(~valid_mask, float(\"-inf\"))\n","\n","    x_ind, y_ind = np.triu_indices(seqlen, minsep)\n","    predictions_upper = predictions[:, x_ind, y_ind]\n","    targets_upper = targets[:, x_ind, y_ind]\n","\n","    topk = seqlen if override_length is None else max(seqlen, override_length)\n","    indices = predictions_upper.argsort(dim=-1, descending=True)[:, :topk]\n","    topk_targets = targets_upper[torch.arange(batch_size).unsqueeze(1), indices]\n","    if topk_targets.size(1) < topk:\n","        topk_targets = F.pad(topk_targets, [0, topk - topk_targets.size(1)])\n","\n","    cumulative_dist = topk_targets.type_as(predictions).cumsum(-1)\n","\n","    gather_lengths = src_lengths.unsqueeze(1)\n","    if override_length is not None:\n","        gather_lengths = override_length * torch.ones_like(\n","            gather_lengths, device=device\n","        )\n","\n","    gather_indices = (\n","        torch.arange(0.1, 1.1, 0.1, device=device).unsqueeze(0) * gather_lengths\n","    ).type(torch.long) - 1\n","\n","    binned_cumulative_dist = cumulative_dist.gather(1, gather_indices)\n","    binned_precisions = binned_cumulative_dist / (gather_indices + 1).type_as(\n","        binned_cumulative_dist\n","    )\n","\n","    pl5 = binned_precisions[:, 1]\n","    pl2 = binned_precisions[:, 4]\n","    pl = binned_precisions[:, 9]\n","    auc = binned_precisions.mean(-1)\n","\n","    return {\"AUC\": auc, \"P@L\": pl, \"P@L2\": pl2, \"P@L5\": pl5}\n","\n","\n","def evaluate_prediction(\n","    predictions: torch.Tensor,\n","    targets: torch.Tensor,\n",") -> Dict[str, float]:\n","    if isinstance(targets, np.ndarray):\n","        targets = torch.from_numpy(targets)\n","    contact_ranges = [\n","        (\"local\", 3, 6),\n","        (\"short\", 6, 12),\n","        (\"medium\", 12, 24),\n","        (\"long\", 24, None),\n","    ]\n","    metrics = {}\n","    targets = targets.to(predictions.device)\n","    for name, minsep, maxsep in contact_ranges:\n","        rangemetrics = compute_precisions(\n","            predictions,\n","            targets,\n","            minsep=minsep,\n","            maxsep=maxsep,\n","        )\n","        for key, val in rangemetrics.items():\n","            metrics[f\"{name}_{key}\"] = val.item()\n","    return metrics"]},{"cell_type":"markdown","metadata":{"id":"cvYiSUg7n5rP"},"source":["### Plotting Results"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pG3gTskUfyfy","executionInfo":{"status":"ok","timestamp":1698083758451,"user_tz":180,"elapsed":24,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"outputs":[],"source":["\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n","def plot_contacts_and_predictions(\n","    predictions: Union[torch.Tensor, np.ndarray],\n","    contacts: Union[torch.Tensor, np.ndarray],\n","    ax: Optional[mpl.axes.Axes] = None,\n","    # artists: Optional[ContactAndPredictionArtists] = None,\n","    cmap: str = \"Blues\",\n","    ms: float = 1,\n","    title: Union[bool, str, Callable[[float], str]] = True,\n","    animated: bool = False,\n",") -> None:\n","\n","    if isinstance(predictions, torch.Tensor):\n","        predictions = predictions.detach().cpu().numpy()\n","    if isinstance(contacts, torch.Tensor):\n","        contacts = contacts.detach().cpu().numpy()\n","    if ax is None:\n","        ax = plt.gca()\n","\n","    seqlen = contacts.shape[0]\n","    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n","    bottom_mask = relative_distance < 0\n","    masked_image = np.ma.masked_where(bottom_mask, predictions)\n","    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n","    predictions = predictions.copy()\n","    predictions[invalid_mask] = float(\"-inf\")\n","\n","    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n","    pred_contacts = predictions >= topl_val\n","    true_positives = contacts & pred_contacts & ~bottom_mask\n","    false_positives = ~contacts & pred_contacts & ~bottom_mask\n","    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n","\n","    if isinstance(title, str):\n","        title_text: Optional[str] = title\n","    elif title:\n","        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n","            \"P@L\"\n","        ].item()\n","        if callable(title):\n","            title_text = title(long_range_pl)\n","        else:\n","            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n","    else:\n","        title_text = None\n","\n","    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n","    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n","    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n","    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n","    ti = ax.set_title(title_text) if title_text is not None else None\n","    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n","\n","    ax.axis(\"square\")\n","    ax.set_xlim([0, seqlen])\n","    ax.set_ylim([0, seqlen])"]},{"cell_type":"markdown","source":["## Get the your protein MSA and structure from databases"],"metadata":{"id":"nmhSNa2S4y3P"}},{"cell_type":"markdown","source":["We can retrieve our sequence from the Myohemerythrin structure in the PDB:"],"metadata":{"id":"x-zNrA106xnt"}},{"cell_type":"code","source":["import os\n","from pathlib import Path\n","from Bio import SeqIO, Entrez\n","seqlist = ['2MHR_A']\n","for n in seqlist:\n","  Entrez.email = 'your.email@uc.cl'\n","  temp = Entrez.efetch(db=\"protein\",rettype=\"fasta\",id=n)\n","  aaseq_out = open(\"2mhr.fasta\",'w')\n","  aaseq = SeqIO.read(temp, format=\"fasta\")\n","  SeqIO.write(aaseq,aaseq_out,\"fasta\")\n","  temp.close()\n","  aaseq_out.close()"],"metadata":{"id":"2_DDAP-U6b_6","executionInfo":{"status":"ok","timestamp":1698083775320,"user_tz":180,"elapsed":2211,"user":{"displayName":"Pablo Galaz Davison","userId":"18088375691220935324"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["We will also need a structure to compare how well did the protocol predicted our contacts, this has to be in the mmCif format:"],"metadata":{"id":"h6n6MQ2E_sIz"}},{"cell_type":"code","source":["from Bio.PDB import PDBList, MMCIFParser, Selection\n","# Specify the PDB ID\n","pdb_id = \"2MHR\"\n","# Download the mmCIF file for the specified PDB ID\n","pdb_list = PDBList()\n","mmcif_file = pdb_list.retrieve_pdb_file(pdb_id, file_format=\"mmCif\")\n","# Parse the mmCIF file\n","parser = MMCIFParser(QUIET=True)\n","structure = parser.get_structure(pdb_id, mmcif_file)\n","# Define a function to filter out non-protein residues (e.g., water and ions)\n","def is_protein(atom):\n","    return atom.get_parent().get_full_id()[3][0] == ' '\n","# Create a new structure containing only the protein atoms\n","protein_structure = Selection.unfold_entities(structure, 'A')\n","# Filter the structure to include only protein atoms\n","protein_structure = [atom for atom in protein_structure if is_protein(atom)]\n","# Now, protein_structure contains only the protein atoms, excluding water and ions\n","!mv /content/mh/2mhr.cif /content/2mhr.cif"],"metadata":{"id":"XlcYIeQ5_41B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's see the myohemerytrhin structure:"],"metadata":{"id":"1w8M9w8uOu9R"}},{"cell_type":"code","source":["import py3Dmol\n","#First we assign the py3Dmol.view as view\n","view=py3Dmol.view()\n","#The following lines are used to add the addModel class\n","#to read the PDB files\n","view.addModel(open('2mhr.cif', 'r').read(),'mmCif')\n","#Here we set the background color as white\n","view.setBackgroundColor('white')\n","#Here we set the visualization style and color\n","view.setStyle({'chain':'A'},{'cartoon': {'colorscheme':'ssJmol'}})\n","#You can activate the labels for each residue if you want\n","#or comment them with a '#' at the beggining of each line if you do not want to\n","view.addResLabels({'resi':'1'},{'fontColor':'white','fontOpacity':1,'showBackground':'true'})\n","view.addResLabels({'resi':'118'},{'fontColor':'white','fontOpacity':1,'showBackground':'true'})\n","\n","#Here we center the molecule for its visualization\n","view.zoomTo()\n","#And we finally visualize the structures using the command below\n","view.show()"],"metadata":{"id":"-Mukf3VEO2Z7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For the MSA, we will do a search with MMSEQS2 in the Colabfold database, one of the biggest out there."],"metadata":{"id":"2nbMu2OhYZAx"}},{"cell_type":"code","source":["%%time\n","#@title Setup Colabfold search\n","unified_memory = True #@param {type:\"boolean\"}\n","import os, time, gc\n","if unified_memory:\n","  ENV = {\"TF_FORCE_UNIFIED_MEMORY\":\"1\", \"XLA_PYTHON_CLIENT_MEM_FRACTION\":\"4.0\"}\n","  for k,v in ENV.items(): os.environ[k] = v\n","if not os.path.isdir(\"params\"):\n","  # get code\n","  print(\"installing ColabDesign\")\n","  os.system(\"(mkdir params; apt-get install aria2 -qq; \\\n","  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n","  tar -xf alphafold_params_2022-12-06.tar -C params; touch params/done.txt )&\")\n","\n","  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@gamma\")\n","  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n","  os.system(\"wget https://raw.githubusercontent.com/sokrypton/ColabFold/main/colabfold/colabfold.py -O colabfold_utils.py\")\n","  #os.system(\"wget https://raw.githubusercontent.com/sokrypton/ColabFold/beta/colabfold/mmseqs/api.py\")\n","\n","  # install hhsuite\n","  print(\"installing HHsuite\")\n","  os.makedirs(\"hhsuite\", exist_ok=True)\n","  os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C hhsuite/\")\n","\n","  # download params\n","  if not os.path.isfile(\"params/done.txt\"):\n","    print(\"downloading AlphaFold params\")\n","    while not os.path.isfile(\"params/done.txt\"):\n","      time.sleep(5)\n","if \"hhsuite\" not in os.environ['PATH']:\n","  os.environ['PATH'] += \":hhsuite/bin:hhsuite/scripts\"\n","\n","import re, tempfile\n","from IPython.display import HTML\n","from google.colab import files\n","import numpy as np\n","from colabdesign import mk_af_model, clear_mem\n","from colabdesign.af.contrib import predict\n","from colabdesign.af.contrib.cyclic import add_cyclic_offset\n","from colabdesign.shared.protein import _np_rmsd, _np_kabsch\n","from colabdesign.shared.plot import plot_pseudo_3D, pymol_cmap\n","\n","\n","import jax\n","import jax.numpy as jnp\n","from colabfold_utils import run_mmseqs2\n","import matplotlib.pyplot as plt\n","import string\n","import numpy as np\n","\n","def clear_mem():\n","  backend = jax.lib.xla_bridge.get_backend()\n","  for buf in backend.live_buffers(): buf.delete()\n","\n","def get_pdb(pdb_code=\"\"):\n","  if pdb_code is None or pdb_code == \"\":\n","    upload_dict = files.upload()\n","    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n","    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n","    return \"tmp.pdb\"\n","  elif os.path.isfile(pdb_code):\n","    return pdb_code\n","  elif len(pdb_code) == 4:\n","    os.makedirs(\"tmp\",exist_ok=True)\n","    os.system(f\"wget -qnc https://files.rcsb.org/download/{pdb_code}.cif -P tmp/\")\n","    return f\"tmp/{pdb_code}.cif\"\n","  else:\n","    os.makedirs(\"tmp\",exist_ok=True)\n","    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v4.pdb -P tmp/\")\n","    return f\"tmp/AF-{pdb_code}-F1-model_v4.pdb\"\n","\n","def run_hhalign(query_sequence, target_sequence, query_a3m=None, target_a3m=None):\n","  with tempfile.NamedTemporaryFile() as tmp_query, \\\n","  tempfile.NamedTemporaryFile() as tmp_target, \\\n","  tempfile.NamedTemporaryFile() as tmp_alignment:\n","    if query_a3m is None:\n","      tmp_query.write(f\">Q\\n{query_sequence}\\n\".encode())\n","      tmp_query.flush()\n","      query_a3m = tmp_query.name\n","    if target_a3m is None:\n","      tmp_target.write(f\">T\\n{target_sequence}\\n\".encode())\n","      tmp_target.flush()\n","      target_a3m = tmp_target.name\n","    os.system(f\"hhalign -hide_cons -i {query_a3m} -t {target_a3m} -o {tmp_alignment.name}\")\n","    X, start_indices = predict.parse_hhalign_output(tmp_alignment.name)\n","  return X, start_indices\n","\n","def run_do_not_align(query_sequence, target_sequence, **arg):\n","  return [query_sequence,target_sequence],[0,0]\n","\n","def run_hhfilter(input, output, id=90, qid=10):\n","  os.system(f\"hhfilter -id {id} -qid {qid} -i {input} -o {output}\")\n","\n","@jax.jit\n","def get_coevolution(X):\n","  '''given one-hot encoded MSA, return contacts'''\n","  Y = jax.nn.one_hot(X,22)\n","  N,L,A = Y.shape\n","  Y_flat = Y.reshape(N,-1)\n","  # covariance\n","  c = jnp.cov(Y_flat.T)\n","\n","  # inverse covariance\n","  shrink = 4.5/jnp.sqrt(N) * jnp.eye(c.shape[0])\n","  ic = jnp.linalg.inv(c + shrink)\n","\n","  # partial correlation coefficient\n","  ic_diag = jnp.diag(ic)\n","  pcc = ic / jnp.sqrt(ic_diag[:,None] * ic_diag[None,:])\n","\n","  raw = jnp.sqrt(jnp.square(pcc.reshape(L,A,L,A)[:,:20,:,:20]).sum((1,3)))\n","  i = jnp.arange(L)\n","  raw = raw.at[i,i].set(0)\n","  # do apc\n","  ap = raw.sum(0,keepdims=True) * raw.sum(1,keepdims=True) / raw.sum()\n","  return (raw - ap).at[i,i].set(0)\n","\n","def plot_3D(aux, Ls, file_name, show=False):\n","  plt.figure(figsize=(10,5))\n","  xyz = aux[\"atom_positions\"][:,1]\n","  xyz = xyz @ _np_kabsch(xyz, xyz, return_v=True, use_jax=False)\n","  ax = plt.subplot(1,2,1)\n","  if len(Ls) > 1:\n","    plt.title(\"chain\")\n","    c = np.concatenate([[n]*L for n,L in enumerate(Ls)])\n","    plot_pseudo_3D(xyz=xyz, c=c, cmap=pymol_cmap, cmin=0, cmax=39, Ls=Ls, ax=ax)\n","  else:\n","    plt.title(\"length\")\n","    plot_pseudo_3D(xyz=xyz, Ls=Ls, ax=ax)\n","  plt.axis(False)\n","  ax = plt.subplot(1,2,2)\n","  plt.title(\"plddt\")\n","  plot_pseudo_3D(xyz=xyz, c=aux[\"plddt\"], cmin=0.5, cmax=0.9, Ls=Ls, ax=ax)\n","  plt.axis(False)\n","  plt.savefig(file_name, dpi=200, bbox_inches='tight')\n","  plt.show() if show else plt.close()"],"metadata":{"cellView":"form","id":"swViuTudX0gP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's print the PDB sequence to use it as input in the colabfold database search."],"metadata":{"id":"Cwnhdqh3Yp0i"}},{"cell_type":"code","source":["!cat 2mhr.fasta"],"metadata":{"id":"cEP8WrZ-Ywr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Colabfold input\n","sequence = \"\" #@param {type:\"string\"}\n","jobname = \"2mhr\" #@param {type:\"string\"}\n","\n","copies = 1\n","#@markdown ----\n","#@markdown **MSA options**\n","msa_method = \"mmseqs2\" #@param [\"mmseqs2\",\"single_sequence\", \"custom_fas\", \"custom_a3m\", \"custom_sto\"]\n","pair_mode = \"unpaired_paired\" #@param [\"unpaired_paired\",\"paired\",\"unpaired\"] {type:\"string\"}\n","#@markdown filtering options\n","cov = 75 #@param [\"0\", \"25\", \"50\", \"75\", \"90\", \"99\"] {type:\"raw\"}\n","id = 90 #@param [\"90\", \"100\"] {type:\"raw\"}\n","qid = 0 #@param [\"0\", \"10\", \"15\", \"20\", \"30\"] {type:\"raw\"}\n","do_not_filter = False #@param {type:\"boolean\"}\n","\n","#@markdown ----\n","template_mode = \"none\"\n","use_templates = template_mode in [\"mmseqs2\",\"custom\"]\n","pdb = \"\"\n","chain = \"A\"\n","rm_template_seq = False\n","propagate_to_copies = True\n","rm_interchain = False\n","do_not_align = False\n","rm_sidechain = rm_sequence = rm_template_seq\n","\n","# filter options\n","sequence = sequence.upper()\n","sequence = re.sub(\"[^A-Z:/()]\", \"\", sequence.upper())\n","sequence = re.sub(\"\\(\",\":(\", sequence)\n","sequence = re.sub(\"\\)\",\"):\", sequence)\n","sequence = re.sub(\":+\",\":\",sequence)\n","sequence = re.sub(\"/+\",\"/\",sequence)\n","sequence = re.sub(\"^[:/]+\",\"\",sequence)\n","sequence = re.sub(\"[:/]+$\",\"\",sequence)\n","jobname = re.sub(r'\\W+', '', jobname)\n","\n","# process sequence\n","sequences = sequence.split(\":\")\n","u_sequences = predict.get_unique_sequences(sequences)\n","u_cyclic = [x.startswith(\"(\") for x in u_sequences]\n","u_sub_lengths = [[len(y) for y in x.split(\"/\")] for x in u_sequences]\n","u_sequences = [x.replace(\"(\",\"\").replace(\")\",\"\").replace(\"/\",\"\") for x in u_sequences]\n","if len(sequences) > len(u_sequences):\n","  print(\"WARNING: use copies to define homooligomers\")\n","u_lengths = [len(x) for x in u_sequences]\n","sub_seq = \"\".join(u_sequences)\n","seq = sub_seq * copies\n","\n","print(\"jobname\",jobname)\n","print(f\"length={u_lengths} copies={copies}\")\n","\n","input_opts = {\"sequence\":u_sequences,\n","              \"copies\":copies,\n","              \"msa_method\":msa_method,\n","              \"pair_mode\":pair_mode,\n","              \"do_not_filter\":do_not_filter,\n","              \"cov\":cov,\n","              \"id\":id,\n","              \"template_mode\":template_mode,\n","              \"propagate_to_copies\":propagate_to_copies}\n","\n","##################\n","# GET MSA\n","##################\n","#os.makedirs(jobname, exist_ok=True)\n","\n","Ls = [len(x) for x in u_sequences]\n","if msa_method == \"mmseqs2\":\n","  msa, deletion_matrix = predict.get_msa(u_sequences, jobname,\n","    mode=pair_mode,\n","    cov=cov, id=id, qid=qid, max_msa=4096,\n","    do_not_filter=do_not_filter,\n","    mmseqs2_fn=lambda *x: run_mmseqs2(*x, user_agent=\"colabdesign/gamma\"),\n","    hhfilter_fn=run_hhfilter)\n","!mv {jobname}/msa.a3m {jobname}.a3m\n","!rm -r {jobname}/\n","if len(msa) > 1:\n","  predict.plot_msa(msa, Ls)\n","  plt.savefig(f\"{jobname}_msa.png\", dpi=200, bbox_inches='tight')\n","  plt.show()\n","print(\"GC\",gc.collect())"],"metadata":{"id":"7pYi5tmHe34I","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6T7Pcz-poDFn"},"source":["## Predict and Visualize"]},{"cell_type":"markdown","metadata":{"id":"WnZSlf1EoGys"},"source":["### Read Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FS8xLDd9ZJfN"},"outputs":[],"source":["# This is where the data is actually read in\n","PDB_IDS = [\"2mhr\"]\n","\n","structures = {\n","    name.lower(): get_structure(PDBxFile.read(rcsb.fetch(name, \"cif\")))[0]\n","    for name in PDB_IDS\n","}\n","\n","contacts = {\n","    name: contacts_from_pdb(structure, chain=\"A\")\n","    for name, structure in structures.items()\n","}\n","\n","msas = {\n","    name: read_msa(f\"{name.lower()}.a3m\")\n","    for name in PDB_IDS\n","}\n","\n","sequences = {\n","    name: msa[0] for name, msa in msas.items()\n","}"]},{"cell_type":"markdown","metadata":{"id":"IohE_rsToQAK"},"source":["### MSA Transformer Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kIiH7a5olI_A"},"outputs":[],"source":["msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n","msa_transformer = msa_transformer.eval().cuda()\n","msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7USWOF2lWwJ"},"outputs":[],"source":["msa_transformer_predictions = {}\n","msa_transformer_results = []\n","for name, inputs in msas.items():\n","    inputs = greedy_select(inputs, num_seqs=128) # can change this to pass more/fewer sequences\n","    msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n","    msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n","    msa_transformer_predictions[name] = msa_transformer.predict_contacts(msa_transformer_batch_tokens)[0].cpu()\n","    metrics = {\"id\": name, \"model\": \"MSA Transformer (Unsupervised)\"}\n","    metrics.update(evaluate_prediction(msa_transformer_predictions[name], contacts[name]))\n","    msa_transformer_results.append(metrics)\n","msa_transformer_results = pd.DataFrame(msa_transformer_results)\n","display(msa_transformer_results)"]},{"cell_type":"markdown","source":["Now we write the **top L** contact predictions into a file.\n","  These contacts will be used to define **non-bonded attractive interactions betweeen residue pairs** in our SBM."],"metadata":{"id":"UiwqFoqiEXrS"}},{"cell_type":"code","source":["out = open(\"predictions.txt\",\"w\")\n","name = PDB_IDS[0]\n","\n","prediction = msa_transformer_predictions[name]\n","target = contacts[name]\n","matrix = prediction.reshape(-1, prediction.shape[-1])\n","for i in range (0,len(matrix[0])):\n","  for j in range (i+1,len(matrix[0])):\n","    out.write(str(i+1)+\" \"+str(j+1)+\" \"+str(matrix[i][j]).replace(\"tensor(\",\"\").replace(\")\",\"\")+\"\\n\")\n","out.close\n","#Now we print the top 118 predictions\n","!sort -grk3 predictions.txt | awk '$1+2<$2' | head -n 118 > predictions_topl.txt\n","!head -n 10 predictions_topl.txt"],"metadata":{"id":"fpjB4tfZER6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","name = PDB_IDS[0]\n","\n","prediction = msa_transformer_predictions[name]\n","target = contacts[name]\n","\n","fig, ax = plt.subplots(figsize=(5, 4))\n","\n","plot_contacts_and_predictions(\n","    prediction, target, ax=ax, title=lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",")\n","\n","plt.show()"],"metadata":{"id":"ED04UgooD3w6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Now its just GROMACS simulations"],"metadata":{"id":"B1hW3ALgGX7V"}},{"cell_type":"markdown","source":["SBM are based on the treatment of **native contacts**, i.e. pairs of residues that fall below a distance cutoff in a given protein structure, as **attractive non-bonded interactions through either Lennard-Jones or Gaussian potentials**, whereas all other non-native interactions are treated as repulsive.\n","\n","In this context, **the use of physical interactions between residue pairs inferred by DCA** instead of experimentally defined native contacts is a natural extension to SBM, due to the simplicity of its attractive component in the energy function.\n","\n","Here, we will use our predicted contacts, along with bonded potentials (bonds, angles and dihedrals) drawn based on secondary structure predictions using **Jpred4**, to generate an SBM that enables protein folding simulations to predict the structure of *T. hennahi* myohemerythrin based on sequence information alone.\n","\n","**NOTE❗️** While the details of sequence-based secondary structure prediction are outside the scope of this tutorial, a good primer is found in the following publication:\n","\n","- Rost, B. (2001). Protein secondary structure prediction continues to rise. Journal of structural biology, 134(2-3), 204-218."],"metadata":{"id":"-CtfwSlvcz4K"}},{"cell_type":"markdown","source":["We first download the precompiled GROMACS that we are going to use."],"metadata":{"id":"y4U7KVasJs6k"}},{"cell_type":"code","source":["# Download and unzip the compressed folder of SBM-enhanced GROMACS\n","!wget https://raw.githubusercontent.com/pb3lab/ibm3202/master/software/gromacs_sbm.tar.gz\n","!tar xzf gromacs_sbm.tar.gz"],"metadata":{"id":"oS0S_N5xGbtG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. We will also need a secondary struture prediction to generate the **bonded interactions** of our SBM. For this, we will visit the [Jpred4 webserver](http://www.compbio.dundee.ac.uk/jpred/index.html), input our sequence in the text box and click on **`Make a Prediction`**, confirm that you still want to make a prediction by clicking on **`Continue`** and then select to **`View simple results in HTML`**.\n","\n","  Then, load the first and second lines of the results obtained by Jpred4 in the following text box."],"metadata":{"id":"5kMhnGngdgVA"}},{"cell_type":"code","source":["#@title Enter the amino acid sequence and predicted secondary structure of your protein\n","sequence = ''  #@param {type:\"string\"}\n","Jpred = ''  #@param {type:\"string\"}\n","f = open(\"Jpred.txt\", \"a\")\n","f.write(sequence+\"\\n\")\n","f.write(Jpred)\n","f.close()"],"metadata":{"cellView":"form","id":"RmjXgi3XG-jC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. The tertiary contacts inferred by DCA and the secondary structure predicted by Jpred4 will now be used to generate our SBM using the script below. The result from this script are:\n","- A **coordinate** file (extension **.gro**), where each residue of the target sequence is represented by a single bead and given initial positions for starting our folding simulations.\n","- A **topology** file (extension **.top**), which contains the non-bonded interactions from the DCA contacts as Gaussian potentials and the bonded interactions (bonds, angles, dihedrals) drawn from the secondary structure prediction as harmonic potentials.\n","\n","  Upon executing this script, you will be asked to indicate a `DCA maximum force factor`, which controls the force of pairwise potentials that will drive protein folding. A good estimate for the strength of coevolutionary interactions is to consider the force factor equivalent to the ratio of $L$ over the number of DCA pairs (factor = $L$/$|$DCA$|$). Thus, **we will use a value of 1.**"],"metadata":{"id":"dbpIBNmLdk89"}},{"cell_type":"markdown","source":["Now we download the scripts for generating the topology, coordinates and instructions for simulations."],"metadata":{"id":"lPCt8y51J2kR"}},{"cell_type":"code","source":["#Downloading all required files\n","!wget https://github.com/pb3lab/ibm3202/raw/master/scripts/dcasbm.py\n","!wget https://github.com/pb3lab/ibm3202/raw/master/scripts/distavg\n","!wget https://github.com/pb3lab/ibm3202/raw/master/files/sbm_calpha_SA_v5_short.mdp"],"metadata":{"id":"9734FlYTHGVw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Then, we generate the topology"],"metadata":{"id":"gSWLvBt3J_sb"}},{"cell_type":"code","source":["!python dcasbm.py Jpred.txt predictions_topl.txt"],"metadata":{"id":"Qne1ksBjHKeU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Lastly, we will use our coordinate and topology files along with a parameter file to set up and run a folding simulation in our SBM-enhanced version of GROMACS.\n","\n","  These simulations start at a high temperature in which the protein is unfolded, and then the system temperature is gradually reduced until the protein reaches an energy minimum where most interactions are satisfied."],"metadata":{"id":"ZpJBRkscdrp9"}},{"cell_type":"code","source":["%%time\n","%%bash\n","source /content/gromacs_sbm/bin/GMXRC\n","#Preparing the binary input for our folding simulation file\n","gmx grompp -f sbm_calpha_SA_v5_short.mdp -c Jpred_calpha.gro -p Jpred_calpha.top -o run.tpr\n","#Running our folding simulation\n","gmx mdrun -deffnm run -nt 1 -noddcheck"],"metadata":{"id":"uPRgf_wKHRqt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. We will now convert our final .gro structure into a PDB file for further comparison with the experimental structure of *T. hennahi* myohemerythrin"],"metadata":{"id":"tk_RodqPd4Xy"}},{"cell_type":"code","source":["%%bash\n","source /content/gromacs_sbm/bin/GMXRC\n","#Converting our final structure from .gro into a PDB file\n","gmx editconf -f run.gro -o predicted.pdb"],"metadata":{"id":"0DJdJThHHWEO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. Once our folding simulation is complete and we have converted our final coordinates onto the PDB file format, we can compare the predicted structure based on sequence information alone with the experimentally determined structure of *T. hennahi* myohemerythrin. For this, we will first perform a structural alignment of both structures.\n","\n","  In the following box, please enter the filename of the experimental structure (including its .pdb extension) and indicate the starting and ending residues that you wish to align (e.g. 1 to 118)\n","  \n","**NOTE❗️** Remember that, typically, the N- and C-termini of a protein structure are very flexible and can be disregarded from the structural alignmen to obtain better results."],"metadata":{"id":"_KXBf7E0d87R"}},{"cell_type":"markdown","source":["### Getting the 2MHR chain A structure"],"metadata":{"id":"6MZA5qkqHscY"}},{"cell_type":"code","source":["from Bio.PDB import PDBList, PDBParser, PDBIO, Select\n","\n","# Specify the PDB ID and chain you want to download\n","pdb_id = \"2MHR\"\n","chain_id = \"A\"\n","\n","# Define a custom Select class to filter protein atoms\n","class ProteinSelector(Select):\n","    def accept_chain(self, chain):\n","        return chain.get_id() == chain_id\n","\n","    def accept_residue(self, residue):\n","        return residue.get_id()[0] == ' '\n","\n","# Download the PDB file for the specified PDB ID\n","pdb_list = PDBList()\n","pdb_file = pdb_list.retrieve_pdb_file(pdb_id, file_format=\"pdb\")\n","\n","# Parse the PDB file\n","parser = PDBParser(QUIET=True)\n","structure = parser.get_structure(pdb_id, pdb_file)\n","\n","# Apply the custom selection to keep only protein atoms\n","io = PDBIO()\n","io.set_structure(structure)\n","io.save(\"experimental.pdb\", select=ProteinSelector())"],"metadata":{"id":"hVC_qtkmHkbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Perform a structural alignment between the predicted and experimental structure\n","\n","import Bio.PDB\n","\n","# Select what residues numbers you wish to align\n","# and put them in a list\n","\n","#@markdown 1. Indicate the starting and ending residues you wish to align\n","\n","start_resi = 17 #@param {type:\"number\"}\n","end_resi   = 118 #@param {type:\"number\"}\n","atoms_to_be_aligned = range(start_resi, end_resi + 1)\n","\n","# Start the parser\n","pdb_parser = Bio.PDB.PDBParser(QUIET = True)\n","\n","#@markdown 2. Indicate the filename of the experimental structure (PDB file)\n","\n","# Get the structures\n","experimental = 'experimental.pdb' #@param {type:\"string\"}\n","predicted = 'predicted.pdb'\n","ref_structure = pdb_parser.get_structure(\"reference\", experimental)\n","sample_structure = pdb_parser.get_structure(\"sample\", predicted)\n","\n","# Use the first model in the pdb-files for alignment\n","# Change the number 0 if you want to align to another structure\n","ref_model    = ref_structure[0]\n","sample_model = sample_structure[0]\n","\n","# Make a list of the atoms (in the structures) you wish to align.\n","# In this case we use CA atoms whose index is in the specified range\n","ref_atoms = []\n","sample_atoms = []\n","\n","# Iterate of all chains in the model in order to find all residues\n","for ref_chain in ref_model:\n","  # Iterate of all residues in each model in order to find proper atoms\n","  for ref_res in ref_chain:\n","    # Check if residue number ( .get_id() ) is in the list\n","    if ref_res.get_id()[1] in atoms_to_be_aligned:\n","      # Append CA atom to list\n","      ref_atoms.append(ref_res['CA'])\n","\n","# Do the same for the sample structure\n","for sample_chain in sample_model:\n","  for sample_res in sample_chain:\n","    if sample_res.get_id()[1] in atoms_to_be_aligned:\n","      sample_atoms.append(sample_res['CA'])\n","\n","# Now we initiate the superimposer:\n","super_imposer = Bio.PDB.Superimposer()\n","super_imposer.set_atoms(ref_atoms, sample_atoms)\n","super_imposer.apply(sample_model.get_atoms())\n","\n","# Print RMSD:\n","print('The calculated RMSD is:')\n","print (super_imposer.rms)\n","\n","# Save the aligned version of one of the chains of 6ANE\n","io = Bio.PDB.PDBIO()\n","io.set_structure(sample_structure)\n","io.save(\"predicted_aligned.pdb\")\n","\n","aligned = 'predicted_aligned.pdb'"],"metadata":{"cellView":"form","id":"N6J55w5iHakD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. Now we can load the superimposed structure into py3dmol with the code cell shown below to visualize the accuracy of our prediction.\n","\n","**QUESTION❓**\n","- How accurate was your prediction when compared to the experimentally solved structure of *T. hennahi* myohemerythrin?\n","- In which ways do you believe that the accuracy of your prediction can be improved?"],"metadata":{"id":"oOtw_2cZIErU"}},{"cell_type":"code","source":["import py3Dmol\n","view=py3Dmol.view()\n","view.addModel(open(experimental, 'r').read(),'pdb')\n","view.setStyle({'chain':'A'},{'cartoon': {'color':'spectrum'}})\n","view.addModel(open(aligned, 'r').read(),'pdb')\n","view.setStyle({'chain':' '},{'cartoon': {'style':'trace','color':'red'}})\n","#You can opt to delete these labels\n","view.addResLabels({'resi':'1'},{'fontColor':'white','fontOpacity':1,'showBackground':'true'})\n","view.addResLabels({'resi':'118'},{'fontColor':'white','fontOpacity':1,'showBackground':'true'})\n","\n","view.zoomTo()\n","view.setBackgroundColor('white')\n","view.show()"],"metadata":{"id":"q1EP8_t_II0r"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["U0ukYqqzateL","IiB2IaU6QyF9","Nad5sAXqREhx","q1eZWXv1bxGl","i7iXPaDKZ5vx","rb4cDoG2ns91","tV3WCbn6aXL7","mqwybh2Tn_Ou","lW5thQpSn0Rp","cvYiSUg7n5rP"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}